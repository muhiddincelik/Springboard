{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Optimize I').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_stock = spark.read.format('csv') \\\n",
    "                        .option(\"inferSchema\", True) \\\n",
    "                        .option(\"header\", False) \\\n",
    "                        .option(\"sep\", ',') \\\n",
    "                .load(\"/FileStore/tables/sales_data/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Perform map operation ####\n",
    "We need to propagate make and year to the accident records (incident type A), using\n",
    "vin_number as the aggregate key. Therefore the map output key should be vin_number, value\n",
    "should be the make and year, along with the incident type. In Spark, in order to proceed with the\n",
    "“groupByKey” function, we need the map operation to produce PairRDD, with tuple type as each\n",
    "record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vin_kv = raw_rdd.map( lambda x: extract_vin_key_value(x))\n",
    "# Please implement method extract_vin_key_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Perform group aggregation to populate make and year to all the records ####\n",
    "Like the reducer in MapReduce framework, Spark provides a “groupByKey” function to achieve\n",
    "shuffle and sort in order to aggregate all records sharing the same key to the same groups.\n",
    "Within a group of vin_number, we need to iterate through all the records and find the one that\n",
    "has the make and year available and capture it in group level master info. As we filter and\n",
    "output accident records, those records need to be modified adding the master info that we\n",
    "captured in the first iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhance_make = vin_kv.groupByKey().flatMap( lambda kv: populate_make(kv[ 1 ]))\n",
    "# Please implement method populate_make()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Perform map operation ####\n",
    "The goal of this step is to count the number of records for each make and year combination,\n",
    "given the result we derived previously. The output key should be the combination of vehicle\n",
    "make and year. The value should be the count of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_kv = enhance_make.map( lambda x: extract_make_key_value(x))\n",
    "# Please implement method extract_make_key_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Aggregate the key and count the number of records in total per key ####\n",
    "Use Spark provided “reduceByKey” function to perform the sum of all the values (1) from each\n",
    "record. As a result, we get the make and year combination key along with its total record count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Save the result to HDFS as text ####\n",
    "The output file should look similar to this.\n",
    "- Nissan-2003,1\n",
    "- BMW-2008,10\n",
    "- MERCEDES-2013,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
